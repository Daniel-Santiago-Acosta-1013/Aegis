"""
Wrapper para w3af - Web Application Attack and Audit Framework
"""

import asyncio
import json
import logging
import tempfile
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from pathlib import Path

from aegis_pentest.utils.process_runner import get_process_runner
from aegis_pentest.utils.logger import get_logger


@dataclass
class W3afResult:
    """Resultado de un escaneo con w3af"""
    target: str
    vulnerabilities: List[Dict[str, Any]]
    crawled_urls: List[str]
    scan_stats: Dict[str, Any]
    profile_used: str
    raw_output: str


class W3afWrapper:
    """Wrapper para la herramienta w3af"""
    
    def __init__(self, config):
        self.config = config
        self.tool_config = config.get_tool_config('w3af')
        self.logger = logging.getLogger(__name__)
        self.process_runner = get_process_runner()
        self.tool_logger = get_logger()
    
    def is_available(self) -> bool:
        """Verifica si w3af está disponible"""
        return self.config.is_tool_available('w3af')
    
    def should_run_against_target(self, target: str, target_type: str, scan_depth: str = 'basic') -> bool:
        """Determina si w3af debe ejecutarse contra el target"""
        # Solo ejecutar en targets web
        if target_type not in ['url', 'domain']:
            return False
        
        # w3af es intensivo, solo ejecutar en escaneos comprensivos o específicamente solicitado
        if scan_depth not in ['comprehensive', 'deep', 'w3af_requested']:
            self.logger.info("w3af omitido - requiere escaneo comprensivo o específico")
            return False
        
        return True
    
    async def quick_scan(self, target: str) -> W3afResult:
        """Escaneo rápido con w3af usando perfil básico"""
        if not self.is_available():
            raise RuntimeError("w3af no está disponible")
        
        self.logger.info(f"Iniciando escaneo rápido w3af de {target}")
        
        # Crear perfil temporal para escaneo rápido
        profile_content = self._create_quick_profile(target)
        profile_path = await self._create_temp_profile(profile_content)
        
        try:
            return await self._run_w3af_with_profile(target, profile_path, 'quick')
        finally:
            # Limpiar archivo temporal
            Path(profile_path).unlink(missing_ok=True)
    
    async def comprehensive_scan(self, target: str) -> W3afResult:
        """Escaneo comprensivo con w3af usando múltiples plugins"""
        if not self.is_available():
            raise RuntimeError("w3af no está disponible")
        
        self.logger.info(f"Iniciando escaneo comprensivo w3af de {target}")
        
        # Crear perfil temporal para escaneo comprensivo
        profile_content = self._create_comprehensive_profile(target)
        profile_path = await self._create_temp_profile(profile_content)
        
        try:
            return await self._run_w3af_with_profile(target, profile_path, 'comprehensive')
        finally:
            # Limpiar archivo temporal
            Path(profile_path).unlink(missing_ok=True)
    
    async def _run_w3af_with_profile(self, target: str, profile_path: str, scan_type: str) -> W3afResult:
        """Ejecuta w3af con un perfil específico"""
        
        # Comando para w3af
        cmd = [
            self.tool_config.get('path', 'w3af_console'),
            '-s', profile_path,  # Script/perfil a ejecutar
            '-y'  # Non-interactive mode
        ]
        
        try:
            process_result = await self.process_runner.run_tool_async(
                tool_name="w3af",
                command=cmd,
                target=target,
                timeout=self.tool_config.get('timeout', 1800)  # 30 minutos para w3af
            )
            
            # w3af puede generar mucho output, incluso en errores
            stdout = "\n".join(process_result.stdout_lines)
            stderr = "\n".join(process_result.stderr_lines)
            full_output = stdout + stderr
            
            # Parsear resultados
            vulnerabilities = self._parse_vulnerabilities(full_output)
            crawled_urls = self._extract_crawled_urls(full_output)
            
            scan_stats = {
                'total_vulnerabilities': len(vulnerabilities),
                'crawled_urls': len(crawled_urls),
                'target': target,
                'scan_type': scan_type,
                'success': process_result.success
            }
            
            result = W3afResult(
                target=target,
                vulnerabilities=vulnerabilities,
                crawled_urls=crawled_urls,
                scan_stats=scan_stats,
                profile_used=scan_type,
                raw_output=full_output
            )
            
            self.logger.info(f"Escaneo w3af completado: {len(vulnerabilities)} vulnerabilidades, {len(crawled_urls)} URLs")
            return result
            
        except Exception as e:
            self.logger.error(f"Error en w3af: {str(e)}")
            raise
    
    async def _create_temp_profile(self, content: str) -> str:
        """Crea un archivo de perfil temporal"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.w3af', delete=False) as f:
            f.write(content)
            return f.name
    
    def _create_quick_profile(self, target: str) -> str:
        """Crea un perfil w3af para escaneo rápido"""
        return f"""
# w3af Quick Scan Profile for {target}

plugins
output console,text_file
output config text_file
set fileName /tmp/w3af_output.txt
back
output config console
set verbose False
back

crawl web_spider
crawl config web_spider
set only_forward False
set ignore_regex .*\\.(gif|jpg|png|css|js|ico|swf)
back

audit xss,sqli,csrf,lfi,rfi
audit config xss
set number_of_checks 3
back

grep password_profiling,credit_cards,ssn

target
set target {target}
back

start
exit
"""
    
    def _create_comprehensive_profile(self, target: str) -> str:
        """Crea un perfil w3af para escaneo comprensivo"""
        return f"""
# w3af Comprehensive Scan Profile for {target}

plugins
output console,text_file
output config text_file
set fileName /tmp/w3af_comprehensive.txt
back

crawl web_spider,dir_file_bruter
crawl config web_spider
set only_forward False
set ignore_regex .*\\.(gif|jpg|png|css|js|ico|swf)
back

audit blind_sqli,buffer_overflow,csrf,dav,eval,file_upload,format_string,frontpage,generic,htaccess_methods,ldapi,lfi,mx_injection,os_commanding,phishing_vector,redos,response_splitting,rfi,ssi,un_ssl,xpath,xss,xst

grep analyze_cookies,blank_body,cache_control,click_jacking,code_disclosure,content_type_options,cors_origin,credit_cards,csp,directory_indexing,dom_xss,error_500,error_pages,file_upload,form_autocomplete,get_emails,headers,html_comments,meta_tags,objects,oracle,password_profiling,path_disclosure,private_ip,ssn,strange_headers,strange_http_codes,strange_parameters,url_session,wsdl_greper

bruteforce basic_auth,form_auth
bruteforce config basic_auth
set usersFile /usr/share/w3af/core/controllers/bruteforce/users.txt
set passwdFile /usr/share/w3af/core/controllers/bruteforce/passwords.txt
back

target
set target {target}
back

start
exit
"""
    
    def _parse_vulnerabilities(self, output: str) -> List[Dict[str, Any]]:
        """Parsea las vulnerabilidades encontradas por w3af"""
        vulnerabilities = []
        lines = output.splitlines()
        
        current_vuln = {}
        in_vulnerability_section = False
        
        for line in lines:
            line = line.strip()
            
            # Detectar inicio de vulnerabilidad
            if any(indicator in line.lower() for indicator in [
                'vulnerability found', 'security issue', 'potential vulnerability',
                'sql injection', 'cross site scripting', 'csrf', 'lfi', 'rfi'
            ]):
                if current_vuln:
                    vulnerabilities.append(current_vuln)
                
                current_vuln = {
                    'id': 'w3af_' + str(len(vulnerabilities) + 1),
                    'severity': self._extract_severity(line),
                    'port': 'N/A',
                    'description': line[:100],
                    'type': 'w3af',
                    'vulnerability_type': self._classify_w3af_vulnerability(line),
                    'url': self._extract_url_from_line(line),
                    'raw_data': {'line': line}
                }
                in_vulnerability_section = True
            
            # Agregar contexto adicional si estamos en una sección de vulnerabilidad
            elif in_vulnerability_section and current_vuln:
                if 'url:' in line.lower() or 'parameter:' in line.lower():
                    current_vuln['raw_data']['context'] = current_vuln['raw_data'].get('context', '') + line + '\n'
                elif len(line) > 10 and not line.startswith('['):
                    current_vuln['description'] = line[:100]
        
        # Agregar la última vulnerabilidad
        if current_vuln:
            vulnerabilities.append(current_vuln)
        
        return vulnerabilities
    
    def _extract_crawled_urls(self, output: str) -> List[str]:
        """Extrae las URLs descubiertas durante el crawling"""
        urls = []
        lines = output.splitlines()
        
        for line in lines:
            # Buscar líneas que contengan URLs
            if 'http://' in line or 'https://' in line:
                # Extraer URL de la línea
                import re
                url_match = re.search(r'https?://[^\s<>"]+', line)
                if url_match:
                    url = url_match.group(0)
                    if url not in urls:
                        urls.append(url)
        
        return urls
    
    def _extract_severity(self, line: str) -> str:
        """Extrae la severidad de una línea de w3af"""
        line_lower = line.lower()
        
        if any(critical in line_lower for critical in ['critical', 'high', 'sql injection', 'rce']):
            return 'HIGH'
        elif any(medium in line_lower for medium in ['medium', 'xss', 'csrf', 'lfi']):
            return 'MEDIUM'
        elif any(low in line_lower for low in ['low', 'info', 'information']):
            return 'LOW'
        else:
            return 'UNKNOWN'
    
    def _classify_w3af_vulnerability(self, line: str) -> str:
        """Clasifica el tipo de vulnerabilidad de w3af"""
        line_lower = line.lower()
        
        if 'sql' in line_lower:
            return 'SQL Injection'
        elif 'xss' in line_lower or 'cross site' in line_lower:
            return 'Cross-Site Scripting'
        elif 'csrf' in line_lower:
            return 'Cross-Site Request Forgery'
        elif 'lfi' in line_lower:
            return 'Local File Inclusion'
        elif 'rfi' in line_lower:
            return 'Remote File Inclusion'
        elif 'upload' in line_lower:
            return 'File Upload'
        elif 'auth' in line_lower:
            return 'Authentication Issue'
        else:
            return 'Web Application Vulnerability'
    
    def _extract_url_from_line(self, line: str) -> str:
        """Extrae URL de una línea de texto"""
        import re
        url_match = re.search(r'https?://[^\s<>"]+', line)
        return url_match.group(0) if url_match else 'N/A'
    
    def get_available_profiles(self) -> Dict[str, str]:
        """Obtiene los perfiles de escaneo disponibles"""
        return {
            'quick': 'Escaneo rápido con plugins básicos (5-10 min)',
            'comprehensive': 'Escaneo completo con todos los plugins (30+ min)',
            'audit_only': 'Solo plugins de auditoría, sin crawling',
            'crawl_only': 'Solo crawling y descubrimiento de contenido'
        } 